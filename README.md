# TSLLMâ€‘BO: Structureâ€‘Aware Behavioral Optimization for Timeâ€‘Series Forecasting with LLMâ€‘Enhanced Reinforcement Learning

> **TL;DR**Â TSLLMâ€‘BO couples largeâ€‘languageâ€‘model (LLM) priors with structureâ€‘aware reinforcement learning to deliver accurate, stable, and generalizable timeâ€‘series forecasts. The repo provides an outâ€‘ofâ€‘theâ€‘box pipeline covering (i) supervised preâ€‘training, (ii) RL behavioral optimization, and (iii) evaluation / inference.

---
## âœ¨ Dataset
https://github.com/thuml/Time-Series-Library

## âœ¨ Key Features

| Feature                                          | Description                                                                                                                                      |
| ------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------ |
| **LLMâ€‘based temporal encoder**                   | Leverages pretrained language knowledge to model longâ€‘range dependencies while remaining modalityâ€‘agnostic.                                      |
| **Structureâ€‘Aware Behavioral Optimization (BO)** | A novel policyâ€‘gradient variant that integrates domainâ€‘specific structure priors (periodicity, trend, crossâ€‘correlation) into the reward design. |
| **Twoâ€‘Stage Training**                           | 1ï¸âƒ£ *Supervised stage* minimises MSE/MAE; 2ï¸âƒ£ *RL stage* fineâ€‘tunes via TSLLMâ€‘BO to improve longâ€‘horizon stability & multiâ€‘objective tradeâ€‘offs. |
| **Plugâ€‘andâ€‘Play Components**                     | Clean abstractions for `data_provider`, custom `layers`, and `models` make it easy to swap new datasets or backbones.                            |
| **DeepSpeed / Accelerate Ready**                 | `ds_config_zero2.json` + launch scripts enable efficient distributed training on multiâ€‘GPU clusters.                                             |

---

## ğŸ—‚ï¸ Directory Layout

```
.
â”œâ”€â”€ data_provider/        # Dataset loaders & data augmentation
â”œâ”€â”€ layers/               # Neural network building blocks (Patch, Attention, etc.)
â”œâ”€â”€ models/               # TSLLM backbone & policy networks
â”œâ”€â”€ scripts/              # Helper scripts (metrics, visualization, export)
â”œâ”€â”€ utils/                # Common utilities (config, logging, checkpoint)
â”œâ”€â”€ ds_config_zero2.json  # DeepSpeedÂ ZeROâ€‘2 config for memoryâ€‘efficient training
â”œâ”€â”€ requirements.txt      # Minimal Python dependencies
â”œâ”€â”€ run_main.py           # Supervised preâ€‘training entry point
â”œâ”€â”€ run_RL_pretrain.py    # Optional warmâ€‘start RL preâ€‘training
â””â”€â”€ run_RL.py             # Structureâ€‘Aware BO fineâ€‘tuning & evaluation
```

---

## ğŸš€ Quick Start

### 1. Environment

```bash
# Create & activate a new virtual env (optional)
python -m venv tsllm_env && source tsllm_env/bin/activate

# Install core dependencies
pip install -r requirements.txt
```

### 2. Prepare Data

1. Place raw *.csv* or *.npz* files under `data_provider/raw/` following the naming convention described in `data_provider/README.md` (or write your own loader).
2. Optionally run `scripts/make_dataset.py` to generate cached *.pkl* files for faster I/O.

### 3. Supervised Preâ€‘Training

```bash
python run_main.py \
    --cfg configs/sft.yaml        # sample YAML listing model & data hyperâ€‘params
```

### 4. RL Behavioral Optimization

```bash
# (Optional) policy/value warmâ€‘start
python run_RL_pretrain.py --cfg configs/rl_warmstart.yaml

# Main BO fineâ€‘tune + evaluation
python run_RL.py --cfg configs/rl_bo.yaml \
                 --deepspeed ds_config_zero2.json
```

Training logs & checkpoints are written to `./output/<run_name>/`.

### 5. Inference

```bash
python scripts/infer.py --ckpt output/best_model.pth --horizon 720
```

---

## âš™ï¸ Configuration Files

All hyperâ€‘parameters are specified in YAML files under `configs/`. Key fields include:

| Field               | Description                                                     |
| ------------------- | --------------------------------------------------------------- |
| `dataset`           | Path & task (e.g., electricity, traffic)                        |
| `model.*`           | Backbone depth, hidden dims, attention heads                    |
| `rl.reward_weights` | \[trend, seasonal, accuracy] weights for multiâ€‘objective reward |
| `optimizer.*`       | Optimiser, LR schedule, gradient clip                           |
| `trainer.*`         | Epochs, eval interval, early stop tolerance                     |

---

## ğŸ“Š Reproducing Paper Results

```bash
bash scripts/run_all.sh   # sequentially executes SFT â†’ RLâ€‘BO across 8 public datasets
```

Our reported scores will be dumped to `results/summary.csv` for easy comparison.

---

## ğŸ“„ License

This project is released under the ApacheÂ 2.0 License. See `LEGAL.md` for details.

---

## ğŸ™ Acknowledgements

We thank the authors of **Timeâ€‘LLM**, **DeepSpeed**, and the **Timeâ€‘SeriesÂ Library** for their openâ€‘source efforts, which our work builds upon.
